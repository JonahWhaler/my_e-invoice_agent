{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import chromadb\n",
    "\n",
    "from llm_agent_toolkit.loader import PDFLoader  # type: ignore\n",
    "from llm_agent_toolkit.encoder import OllamaEncoder  # type: ignore\n",
    "from llm_agent_toolkit.memory import ChromaMemory  # type: ignore\n",
    "from llm_agent_toolkit._memory import ShortTermMemory  # type: ignore\n",
    "from llm_agent_toolkit.core.local import Image_to_Text  # type: ignore\n",
    "from llm_agent_toolkit import ChatCompletionConfig  # type: ignore\n",
    "from agents import EInvoiceAgent\n",
    "from tools import DDGSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename=\"./output/log/cookbook-1.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knowledge_base(\n",
    "    mem: ChromaMemory, ldr: PDFLoader, src_dir: str, web_search: DDGSearch, topic: str\n",
    "):\n",
    "    logger.info(\"Building knowledge base...\")\n",
    "    files = os.listdir(src_dir)\n",
    "    for f in files:\n",
    "        filepath = os.path.join(src_dir, f)\n",
    "        logger.info(\"Loading from %s\", filepath)\n",
    "        f_content = ldr.load(input_path=filepath)\n",
    "        logger.info(\"Adding to memory...\")\n",
    "        mem.add(document_string=f_content, metadata={\"filename\": f})\n",
    "\n",
    "    params = {\"query\": topic, \"top_n\": 20}\n",
    "    text_result = web_search.run(json.dumps(params))\n",
    "    pages = text_result.split(\"$$$$$$$\")\n",
    "    for page in pages:\n",
    "        page_object = json.loads(page.strip())\n",
    "        metadata = {\"filename\": page_object[\"title\"]}\n",
    "        p_content = f\"Body={page_object['body']}\\nHTML={page_object['html']}\"\n",
    "        p_content = p_content.replace(\"\\n\\n\\n\\n\", \"\\n\")\n",
    "        mem.add(document_string=p_content, metadata=metadata)\n",
    "\n",
    "    logger.info(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = r\"./assets\"\n",
    "TMP_DIRECTORY = \"./output\"\n",
    "PROJECT_NAME = \"cookbook-1\"\n",
    "NAMESPACE = \"my-einv-2\"\n",
    "OLLAMA_HOST = \"http://localhost:11434\"\n",
    "OVERWRITE = True\n",
    "TOPIC = \"Malaysia e-Invoice Guidelines, SDK\"\n",
    "SPLIT_TEXT_CONFIG = {\"chunk_size\": 2048, \"stride_rate\": 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_GENERATION_PROMPT = \"\"\"\n",
    "You are a grading assistant. Your task is to evaluate the correlation between a user query and a knowledge segment retrieved via semantic search.\n",
    "\n",
    "Analyze the semantic and contextual relationship between the user query and the knowledge segment.\n",
    "Provide a score between 0.0 and 1.0 to represent the correlation:\n",
    "    0.0: Completely unrelated.\n",
    "    1.0: Perfectly related and fully relevant.\n",
    "Justify your score with a concise reason.\n",
    "\n",
    "Input Format:\n",
    "User Query: \"<insert user query here>\" Knowledge Segment: \"<insert knowledge segment here>\"\n",
    "\n",
    "Output Format (JSON):\n",
    "{\n",
    "  \"reason\": \"<string>\"\n",
    "  \"score\": <float>,\n",
    "}\n",
    "\n",
    "Note:\n",
    "- Return only in JSON format with \"reason\" and \"score\" as keys. Nothing else!!!\n",
    "\"\"\"\n",
    "\n",
    "POST_GENERATION_PROMPT = \"\"\"\n",
    "You are a grounding validator. Your task is to evaluate the grounding of an LLM response based on the provided context.\n",
    "\n",
    "Compare the LLM response against the context to determine if the response is factually supported and aligns with the given information.\n",
    "Provide a score between 0.0 and 1.0:\n",
    "    0.0: Completely hallucinated or unsupported by the context.\n",
    "    1.0: Fully grounded in the context and factually accurate.\n",
    "Justify your score with a concise explanation that highlights specific aspects of the response and context.\n",
    "\n",
    "Input Format:\n",
    "LLM Response: \"<insert LLM response here>\" Context: \"<insert context here>\"\n",
    "\n",
    "Output Format (JSON):\n",
    "{\n",
    "  \"reason\": \"<string>\"\n",
    "  \"score\": <float>,\n",
    "}\n",
    "\n",
    "Note:\n",
    "- Return only in JSON format with \"reason\" and \"score\" as keys. Nothing else!!!\n",
    "\"\"\"\n",
    "\n",
    "IMAGE_INTERPRETOR_PROMPT = \"\"\"\n",
    "You are an image interpreter. Your task is to analyze and describe the provided image, whether it is a photograph or a diagram. Your description should comprehensively include:\n",
    "- Image Type: State whether the image is a photo, diagram, chart, or another type.\n",
    "- Foreground Elements: Identify and describe the primary objects, people, subjects, or components in focus.\n",
    "- Background Elements: For photos, describe the setting or environment. For diagrams, describe any supporting elements like labels, annotations, or grids.\n",
    "- Vibe and Atmosphere: If the image is a photo, explain the overall mood, tone, or emotional impression. If it is a diagram, describe its purpose or functional intent (e.g., instructional, explanatory).\n",
    "- Interactions: For photos, highlight actions, movements, or dynamics between elements. For diagrams, explain how the components relate, interact, or connect logically.\n",
    "- Relationships: Explain the connections or contextual significance between elements (e.g., people interacting in photos, or flow and dependencies in diagrams).\n",
    "\n",
    "Output Example (Photo): \"The image shows a bustling city street in the foreground, with people crossing a zebra crossing. The background includes tall skyscrapers under a clear blue sky. The vibe is energetic and lively. People are interacting by talking and walking together, suggesting a morning rush. The relation between the elements shows a harmonious urban scene with people and vehicles coexisting.\"\n",
    "\n",
    "Output Example (Diagram): \"The image is a flowchart showing a process with five connected nodes. The foreground features circles and arrows labeled with text. The background is plain white with no decorative elements. The purpose is instructional, conveying the sequence of steps in a workflow. Interactions are depicted through arrows showing directional flow, and relationships highlight dependencies between nodes.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb = chromadb.Client(\n",
    "    settings=chromadb.Settings(\n",
    "        is_persistent=True, persist_directory=f\"{TMP_DIRECTORY}/storage/chroma\"\n",
    "    )\n",
    ")\n",
    "\n",
    "local_encoder = OllamaEncoder(\n",
    "    connection_string=OLLAMA_HOST,\n",
    "    model_name=OllamaEncoder.SUPPORTED_MODELS[0][\"name\"],\n",
    ")\n",
    "chroma_memory = ChromaMemory(\n",
    "    vdb=vdb,\n",
    "    encoder=local_encoder,\n",
    "    split_text_config=SPLIT_TEXT_CONFIG,\n",
    "    namespace=NAMESPACE,\n",
    "    overwrite=OVERWRITE,\n",
    ")\n",
    "print(f\"chroma_memory: {chroma_memory}\")\n",
    "i2t = Image_to_Text(\n",
    "    connection_string=OLLAMA_HOST,\n",
    "    system_prompt=IMAGE_INTERPRETOR_PROMPT,\n",
    "    config=ChatCompletionConfig(name=\"llava:7b\", temperature=0.3, max_tokens=1024),\n",
    "    tools=None,\n",
    ")\n",
    "pdf_loader = PDFLoader(text_only=False, tmp_directory=TMP_DIRECTORY, core=i2t)\n",
    "ddg = DDGSearch(region=\"my\", safe_search=\"on\", pause_second=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_knowledge_base(chroma_memory, pdf_loader, DIR, ddg, TOPIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_config = {\n",
    "    \"core\": {\n",
    "        \"connection_string\": OLLAMA_HOST,\n",
    "        \"system_prompt\": \"You are an agent expert in Malaysia e-Invoice implementation.\",\n",
    "        \"config\": ChatCompletionConfig(\n",
    "            name=\"qwen2.5:7b\", max_tokens=128_000, temperature=0.5\n",
    "        ),\n",
    "        \"tools\": [ddg],\n",
    "    },\n",
    "    \"pre-filter\": {\n",
    "        \"connection_string\": OLLAMA_HOST,\n",
    "        \"system_prompt\": PRE_GENERATION_PROMPT,\n",
    "        \"config\": ChatCompletionConfig(\n",
    "            name=\"llama3.2:3b\", max_tokens=512, temperature=0.3\n",
    "        ),\n",
    "        \"threshold\": 0.4,\n",
    "    },\n",
    "    \"post-filter\": {\n",
    "        \"connection_string\": OLLAMA_HOST,\n",
    "        \"system_prompt\": POST_GENERATION_PROMPT,\n",
    "        \"config\": ChatCompletionConfig(\n",
    "            name=\"llama3.2:3b\", max_tokens=512, temperature=0.3\n",
    "        ),\n",
    "        \"threshold\": 0.4,\n",
    "    },\n",
    "}\n",
    "\n",
    "agent = EInvoiceAgent(\n",
    "    short_memory=ShortTermMemory(max_entry=50),\n",
    "    vector_memory=chroma_memory,\n",
    "    config=agent_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $ \\ * + * /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{TMP_DIRECTORY}/{PROJECT_NAME}-progress.md\", \"w\", encoding=\"utf-8\") as progress:\n",
    "    with open(f\"./{PROJECT_NAME}-questions.txt\", \"r\", encoding=\"utf-8\") as reader:\n",
    "        questions = reader.readlines()\n",
    "        for qi, question in enumerate(questions, start=1):\n",
    "            bot_answer = agent.ask(query=question)\n",
    "            progress.write(f\"[{qi}] Question: {question}\\nAnswer: {bot_answer}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
